<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>data efficient offline reinforcement learning literature survey | Feyza Eksen</title> <meta name="author" content="Feyza Eksen"/> <meta name="description" content="data efficient offline reinforcement learning literature survey"/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/me_green.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://feyza-droid.github.io/posts/2022/data-efficient-offline-rl-literature-survey/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/monokai.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Feyza </span>Eksen</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/posts/">posts<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/books/">books</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">data efficient offline reinforcement learning literature survey</h1> <p class="post-meta">October 21, 2022</p> <p class="post-tags"> <a href="/posts/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/posts/tag/reinforcement-learning"> <i class="fas fa-hashtag fa-sm"></i> reinforcement-learning</a>   <a href="/posts/tag/offline-reinforcement-learning"> <i class="fas fa-hashtag fa-sm"></i> offline-reinforcement-learning</a>     ·   <a href="/posts/category/research"> <i class="fas fa-tag fa-sm"></i> research</a>   </p> </header> <article class="post-content"> <h4 id="paper-list">PAPER LIST</h4> <ul> <li><a href="https://" target="_blank" rel="noopener noreferrer">Deep Learning on a Data Diet: Finding Important Examples Early in Training</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Dataset Pruning: Reducing Training Data by Examining Generalization Influence</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Impact of Data Pruning on Machine Learning Algorithm Performance</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Data-Efficient Hierarchical Reinforcement Learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Beyond neural scaling laws beating power law scaling via data pruning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Data pruning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Don't Change the Algorithm, Change the Data Exploratory Data for Offline Reinforcement Learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Prioritized Experience Replay</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">What Matters in Learning from Offline Human Demonstrations for Robot Manipulation</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Estimating Training Data Influence by Tracing Gradient Descent</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">PerSim: Data-Efficient Offline Reinforcement Learning with Heterogeneous Agents via Personalized Simulators</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Data-Efficient Offline Reinforcement Learning with Heterogeneous Agents</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Conservative Q-Learning for Offline Reinforcement Learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">D4RL: datasets for deep data-driven reinforcement learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">DeepMind Control Suite</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Improving DDPG via Prioritized Experience Replay</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Model Selection for Offline Reinforcement Learning: Practical Considerations for Healthcare Settings</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Multi-Task Offline Reinforcement Learning with Conservative Data Sharing</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Offline RL: Approaching Reinforcement Learning in a data-driven manner</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">RL Unplugged: A Suite of Benchmarks for Offline Reinforcement Learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Single-Shot Pruning for Offline Reinforcement Learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Diversity is all you need: Learning skills without a reward function</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">URLB: unsupervised reinforcement learning benchmark</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Aps: Active pretraining with successor feature</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Reinforcement learning with prototypical representations</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Hindsight Experience Replay</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Data-Efficient Pipeline for Offline Reinforcement Learning with Limited Data</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Representation Matters: Offline Pretraining for Sequential Decision Making</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Pretraining Representations for Data-Efficient Reinforcement Learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Dataset Pruning for Resource-constrained Spoofed Audio Detection</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Conservative Data Sharing for Multi-Task Offline Reinforcement Learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Data Valuation for Offline Reinforcement Learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Can Wikipedia Help Offline Reinforcement Learning?</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">DeepThermal: Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning</a></li> <li><a href="https://" target="_blank" rel="noopener noreferrer">OFFLINE REINFORCEMENT LEARNING HANDS-ON</a></li> </ul> <hr> <h4 id="to-do-list">TO-DO LIST</h4> <ul> <li>organize papers (eliminate them by reading their abstracts and add new papers by searching for the most relavant and up-to-date literature on this topic</li> <li>summarize them with the first pass (abstract, overall idea and figures)</li> <li>add link to each paper</li> </ul> <blockquote> TO-DO: My understanding of each paper </blockquote> <hr> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Feyza Eksen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Icons from <a href="https://picrew.me/image_maker/137904" target="_blank" rel="noopener noreferrer">Picrew</a>. Last updated: December 26, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>